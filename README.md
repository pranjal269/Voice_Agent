# Voice Agent - AI-Powered Voice & Speech Processing Platform

## ğŸ“ Day 14 Update: Refactored & Production-Ready! 

This project has been completely refactored for better maintainability, readability, and scalability. The codebase now follows best practices with proper separation of concerns, comprehensive logging, and modular architecture.

## Problem Statement
In today's digital landscape, there's a growing need for accessible and efficient voice-based interactions. Many users and developers face challenges with:
- Converting text to natural-sounding speech
- Recording and processing voice inputs
- Transcribing spoken content to text
- Managing audio files and transcriptions effectively
- Building conversational AI systems

## Project Overview
Voice Agent is a comprehensive web application that combines Text-to-Speech (TTS), Speech-to-Text (STT), and Large Language Model (LLM) capabilities for natural voice conversations with AI. The platform offers:

### Key Features
1. **Conversational AI Agent**
   - Natural voice conversations with AI using Google Gemini
   - Session-based conversation history
   - Automatic speech recognition and response generation
   - Fallback handling for service failures

2. **Text-to-Speech Generation**
   - Convert written text to natural-sounding speech using Murf AI
   - Support for multiple voices and languages
   - Real-time audio preview and playback
   - Character limit management (up to 5000 characters)

3. **Speech-to-Text Processing**
   - Convert recorded speech to text using AssemblyAI
   - Support for multiple audio formats (WebM, WAV, MP3, M4A, OGG, Opus)
   - Real-time transcription with error handling

4. **Professional UI/UX**
   - Clean, intuitive design with responsive feedback
   - Real-time recording controls with visual indicators
   - Session management and conversation history
   - Auto-recording for seamless conversations

### ğŸ—ï¸ Refactored Architecture
The application now features a clean, modular architecture:

```
app/
â”œâ”€â”€ core/               # Core configuration and utilities
â”‚   â”œâ”€â”€ config.py      # Environment & settings management
â”‚   â””â”€â”€ logging.py     # Centralized logging setup
â”œâ”€â”€ models/            # Pydantic models for request/response
â”‚   â””â”€â”€ schemas.py     # API schemas and validation
â”œâ”€â”€ services/          # Third-party service integrations
â”‚   â”œâ”€â”€ tts.py        # Murf AI Text-to-Speech service
â”‚   â”œâ”€â”€ stt.py        # AssemblyAI Speech-to-Text service
â”‚   â”œâ”€â”€ llm.py        # Google Gemini LLM service
â”‚   â””â”€â”€ chat_session.py # Session management
â””â”€â”€ routers/           # API endpoint handlers
    â”œâ”€â”€ tts.py        # TTS endpoints
    â”œâ”€â”€ stt.py        # STT endpoints
    â”œâ”€â”€ llm.py        # LLM endpoints
    â””â”€â”€ chat.py       # Chat session endpoints
```

### Technical Stack
- **Backend**: Python 3.11+ with FastAPI
- **Frontend**: HTML5, CSS3, Vanilla JavaScript
- **AI Services**: 
  - Google Gemini for LLM responses
  - Murf AI for Text-to-Speech
  - AssemblyAI for Speech-to-Text
- **Audio Processing**: WebAudio API, MediaRecorder API
- **Architecture**: Clean Architecture, Dependency Injection, Service Layer Pattern

### Key Improvements in Refactor
- âœ… **Pydantic Models**: Proper request/response validation and documentation
- âœ… **Service Layer**: Separated third-party integrations into dedicated services
- âœ… **Comprehensive Logging**: Structured logging with colored console output
- âœ… **Error Handling**: Robust error handling with fallback responses
- âœ… **Configuration Management**: Environment-based configuration
- âœ… **Session Management**: Proper conversation history handling
- âœ… **API Documentation**: Auto-generated OpenAPI/Swagger documentation
- âœ… **Modular Routing**: Organized endpoints by feature

## Getting Started

### Prerequisites
- Python 3.11 or higher
- API keys for:
  - Google Gemini (GEMINI_API_KEY)
  - Murf AI (MURF_API_KEY) 
  - AssemblyAI (ASSEMBLYAI_API_KEY)

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/pranjal269/Voice_Agent.git
   cd Voice_Agent
   ```

2. Set up environment variables in `.env` file:
   ```env
   GEMINI_API_KEY=your_gemini_api_key
   MURF_API_KEY=your_murf_api_key
   ASSEMBLYAI_API_KEY=your_assemblyai_api_key
   DEBUG=false
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the application:
   ```bash
   # Main application
   python main.py
   
   # Or using uvicorn directly
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

5. Open your browser and navigate to:
   - Main App: http://localhost:8000
   - API Documentation: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

## API Endpoints

### Core Endpoints
- `POST /tts/generate` - Generate speech from text
- `POST /stt/transcribe` - Transcribe audio to text
- `POST /llm/query` - Query LLM with text or audio
- `POST /agent/chat/{session_id}` - Conversational AI chat
- `GET /health` - System health check

### Legacy Compatibility
The refactored version maintains backward compatibility with the original endpoints. The original implementation is preserved in `main_original.py` for reference.

## Usage Examples

### Text-to-Speech
```bash
curl -X POST "http://localhost:8000/tts/generate" \
     -H "Content-Type: application/json" \
     -d '{"text": "Hello, this is a test!", "voiceId": "en-US-natalie"}'
```

### Speech-to-Text
```bash
curl -X POST "http://localhost:8000/stt/transcribe" \
     -F "file=@audio.wav"
```

### Conversational AI
```bash
curl -X POST "http://localhost:8000/agent/chat/my-session-123" \
     -F "file=@voice_input.webm" \
     -F "model=gemini-1.5-flash" \
     -F "temperature=0.7"
```

## Development

### Project Structure
```
voice-agent/
â”œâ”€â”€ app/                    # Refactored application code
â”‚   â”œâ”€â”€ core/              # Core utilities and configuration
â”‚   â”‚   â”œâ”€â”€ config.py      # Environment & settings management
â”‚   â”‚   â””â”€â”€ logging.py     # Centralized logging setup
â”‚   â”œâ”€â”€ models/            # Pydantic schemas for validation
â”‚   â”‚   â””â”€â”€ schemas.py     # API request/response models
â”‚   â”œâ”€â”€ services/          # Service layer for external APIs
â”‚   â”‚   â”œâ”€â”€ tts.py        # Murf AI Text-to-Speech service
â”‚   â”‚   â”œâ”€â”€ stt.py        # AssemblyAI Speech-to-Text service
â”‚   â”‚   â”œâ”€â”€ llm.py        # Google Gemini LLM service
â”‚   â”‚   â””â”€â”€ chat_session.py # Session management
â”‚   â””â”€â”€ routers/           # API endpoint handlers
â”‚       â”œâ”€â”€ tts.py        # TTS endpoints
â”‚       â”œâ”€â”€ stt.py        # STT endpoints
â”‚       â”œâ”€â”€ llm.py        # LLM endpoints
â”‚       â””â”€â”€ chat.py       # Chat session endpoints
â”œâ”€â”€ static/                # Frontend assets
â”‚   â””â”€â”€ script.js         # Enhanced voice agent UI
â”œâ”€â”€ templates/             # HTML templates
â”‚   â””â”€â”€ index.html        # Main application interface
â”œâ”€â”€ uploads/               # File upload directory
â”œâ”€â”€ main.py               # Main FastAPI application (refactored)
â”œâ”€â”€ main_original.py      # Original implementation (reference)
â”œâ”€â”€ test_app.py           # Application tests
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .gitignore           # Git ignore rules
â””â”€â”€ README.md            # This documentation
```

### Logging
The application includes comprehensive logging:
- Console output with colored formatting
- File logging to `logs/voice_agent.log`
- Different log levels for development and production

### Error Handling
- Graceful fallback responses when services fail
- Proper HTTP status codes and error messages
- Retry logic for transient failures

## Deployment

### Environment Variables
```env
# Required API Keys
GEMINI_API_KEY=your_google_gemini_api_key
MURF_API_KEY=your_murf_ai_api_key  
ASSEMBLYAI_API_KEY=your_assemblyai_api_key

# Optional Configuration
DEBUG=false
```

### Production Considerations
- Set `DEBUG=false` in production
- Configure CORS origins appropriately
- Use a reverse proxy (nginx) for static files
- Set up proper logging rotation
- Consider rate limiting for API endpoints

## API Documentation
Visit http://localhost:8000/docs for interactive API documentation powered by Swagger UI.

## Future Enhancements
- Support for additional voice models and languages
- Advanced audio editing features
- Batch processing capabilities
- Voice emotion detection
- Custom voice model training

---
Built with â¤ï¸ by Pranjal | #30DaysOfCode
